{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dataframe with image_path, time(seconds) and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* In the video given, we have ~344 (5min 44s) seconds of video. \n",
    "* Our ground truth labels correspond to a video that is 12m 12s (~732seconds). \n",
    "* We only have a portion of that video. \n",
    "* It appears that our framerate <strong>~ 13 fps </strong>. (4459 frames * (1 second / 13frames) = 344 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4459"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/driving.csv')\n",
    "df.head(10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = df[3541:4459]\n",
    "train_data = df[0:3540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFyCAYAAAB/b0lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIicvT/AVfCvj/DgRgeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71044d80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.asarray(df['time'], dtype = np.float32)\n",
    "speeds = np.asarray(df['speed'], dtype=np.float32)\n",
    "plt.plot(times, speeds, 'r-')\n",
    "plt.title('Speed vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>./data/IMG/344.3211498260498.jpg</td>\n",
       "      <td>344.321150</td>\n",
       "      <td>27.928958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>./data/IMG/344.37305998802185.jpg</td>\n",
       "      <td>344.373060</td>\n",
       "      <td>27.938640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>./data/IMG/344.5106108188629.jpg</td>\n",
       "      <td>344.510611</td>\n",
       "      <td>27.932405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>./data/IMG/344.5854048728943.jpg</td>\n",
       "      <td>344.585405</td>\n",
       "      <td>27.927574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>./data/IMG/344.63681387901306.jpg</td>\n",
       "      <td>344.636814</td>\n",
       "      <td>27.847842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image_path        time      speed\n",
       "4454   ./data/IMG/344.3211498260498.jpg  344.321150  27.928958\n",
       "4455  ./data/IMG/344.37305998802185.jpg  344.373060  27.938640\n",
       "4456   ./data/IMG/344.5106108188629.jpg  344.510611  27.932405\n",
       "4457   ./data/IMG/344.5854048728943.jpg  344.585405  27.927574\n",
       "4458  ./data/IMG/344.63681387901306.jpg  344.636814  27.847842"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_perspective_transform(image):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (256, 256, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             2) Perspective transform\n",
    "             3) resize to (256, 256, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "    \n",
    "    # TODO: Write perspective transform \n",
    "#     perspective = apply_perspective_transform(image_cropped)\n",
    "    \n",
    "    image = cv2.resize(image_cropped, (227, 227), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img = change_brightness(img)\n",
    "\n",
    "            \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 227, 227, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.randint(len(data) - 1)\n",
    "            row1 = data.iloc[[idx]].reset_index()\n",
    "            row2 = data.iloc[[idx + 1]].reset_index()\n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "           \n",
    "            # stack images\n",
    "            x = np.concatenate(x1, x2, axis = 0)\n",
    "            \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = x\n",
    "            label_batch[i] = y\n",
    "            \n",
    "        yield shuffle(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack mode\n",
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(len(data) - 1):\n",
    "            row1 = data.iloc[[idx]].reset_index()\n",
    "            row2 = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            s1 = row1['speed'].values[0]\n",
    "            s2 = row2['speed'].values[0]\n",
    "            \n",
    "            # Stack the images to send into the model\n",
    "            img_stack = np.concatenate(x1, x2, axis = 0)\n",
    "            \n",
    "            img_stack = img_stack.reshape(1, img_stack.shape[0], img_stack.shape[1], img_stack.shape[2])\n",
    "            \n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            yield img_stack, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture (DeepVO AlexNetLike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Channel Normalization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers.core import  Lambda, Merge\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.engine import Layer\n",
    "\n",
    "def crosschannelnormalization(alpha = 1e-4, k=2, beta=0.75, n=5,**kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        b, ch, r, c = X.shape\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0,2,3,1))\n",
    "                                              , (0,half))\n",
    "        extra_channels = K.permute_dimensions(extra_channels, (0,3,1,2))\n",
    "        scale = k\n",
    "        for i in range(n):\n",
    "            scale += alpha * extra_channels[:,i:i+ch,:,:]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape:input_shape,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation, Flatten, merge, Lambda, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from CustomLayers import LRN2D\n",
    "\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "N_img_height = 227\n",
    "N_img_width = 227\n",
    "N_img_channels = 3\n",
    "\n",
    "# inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "def splitTensor(tensor):\n",
    "    \"\"\"\n",
    "    Out inputs come in as two stacked (?, 227, 227 ,3) images \n",
    "    tensor shape: (?, 454, 227, 3)\n",
    "    output: split1: tensor (?, 227, 227, 3)\n",
    "            split2: tensor (?, 227, 227, 3)\n",
    "    \"\"\"\n",
    "    split1 = tensor[:, 0:227,:,:]\n",
    "    split2 = tensor[:, 227:454,:,:]\n",
    "    return split1, split2\n",
    "    \n",
    "\n",
    "def DeepVo():\n",
    "    # TODO: Maybe add zeroPadding2D(1, 1) after each layer\n",
    "    # TODO: Maybe take out input_shape = inputShape from first conv layer\n",
    "    \n",
    "    ALPHA = 0.00001\n",
    "    BETA = 0.75\n",
    "    DIM_ORDERING = 'tf'\n",
    "    \n",
    "    \n",
    "    inputShape = (N_img_height * 2, N_img_width, N_img_channels)\n",
    "    inputShapeSingle = (N_img_height, N_img_width, N_img_channels)\n",
    "    \n",
    "    inputImg = Input(shape = inputShape)\n",
    "    \n",
    "#     x = Lambda(lambda x: x / 127.5 - 1, input_shape = inputShape)\n",
    "    \n",
    "#     print('inputImg shape:: ', inputImg.get_shape)\n",
    "    \n",
    "    x, y = splitTensor(inputImg)\n",
    "    \n",
    "    x = Lambda(lambda a: a / 127.5 - 1, input_shape = inputShapeSingle)(x)\n",
    "    \n",
    "    y = Lambda(lambda b: b / 127.5 - 1, input_shape = inputShapeSingle)(y)\n",
    "    \n",
    "#     print('x shape: ', x.get_shape)\n",
    "#     print('y shape: ', y.get_shape)\n",
    "    print(type(x))\n",
    "    \n",
    "    ######## LAYER 1 ####################\n",
    "    # Convolution Layer 1: Channel 1\n",
    "    x1 = Convolution2D(96, 11, 11, subsample=(4, 4), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu',\n",
    "                      input_shape = inputShapeSingle,  # may not be necessary\n",
    "                      name = 'conv_1_x')(x)\n",
    "\n",
    "    # Convolution Layer 1: Channel 2\n",
    "    y1 = Convolution2D(96, 11, 11, subsample=(4, 4), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu',\n",
    "                      input_shape = inputShapeSingle,  # may not be necessary\n",
    "                      name = 'conv_1_y')(y)\n",
    "    ### TODO: ADD NORMALIZATION to X1\n",
    "#     x1 = crosschannelnormalization(x1)\n",
    "    \n",
    "    \n",
    "    ### TODO: ADD NORMALIZATION TO Y1\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 1\n",
    "    x1 = MaxPooling2D((3, 3), strides = (2, 2), dim_ordering=DIM_ORDERING)(x1)\n",
    "    # Max Pooling Layer 1: Channel 2\n",
    "    y1 = MaxPooling2D((3, 3), strides = (2, 2), dim_ordering=DIM_ORDERING)(y1)\n",
    "    ######## END OF LAYER 1 ####################\n",
    "\n",
    "    ######## LAYER 2####################\n",
    "    # Convolution Layer 2: Channel 1\n",
    "    x1 = Convolution2D(256, 5, 5, subsample = (1, 1), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu', \n",
    "                      name = 'conv_2_x')(x1)\n",
    "\n",
    "    # Convolution Layer 2: Channel 2\n",
    "    y1 = Convolution2D(256, 5, 5, subsample = (1, 1), \n",
    "                      init = 'he_normal', \n",
    "                      border_mode = 'valid', \n",
    "                      activation = 'relu', \n",
    "                      name = 'conv_2_y')(y1)\n",
    "    \n",
    "    # Zero Padding (2, 2) on ConvLayer2: Channel 1\n",
    "    x1 = ZeroPadding2D(padding = (2, 2), dim_ordering=DIM_ORDERING)(x1)\n",
    "\n",
    "    # Zero Padding (2, 2) on ConvLayer2: Channel 2\n",
    "    y1 = ZeroPadding2D(padding = (2, 2), dim_ordering=DIM_ORDERING)(y1)\n",
    "    \n",
    "    #TODO: Add cross channel normalizations\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 1\n",
    "    x1 = MaxPooling2D((3, 3), strides = (2, 2))(x1)\n",
    "    \n",
    "    # Max Pooling Layer 1: Channel 2\n",
    "    y1 = MaxPooling2D((3, 3), strides = (2, 2))(y1)\n",
    "    \n",
    "    ####### LAYER 3 ###################\n",
    "    # Convolution Layer 3: Channel 1\n",
    "    x1 = Convolution2D(384, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_3_x')(x1)\n",
    "\n",
    "    # Convolution Layer 3: Channel 2\n",
    "    y1 = Convolution2D(384, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_3_y')(y1)\n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 3 channel 1\n",
    "    x1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(x1)\n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 3 channel 2\n",
    "    y1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(y1)\n",
    "    \n",
    "    \n",
    "    ####### LAYER 4 ###################\n",
    "    # Convolution Layer 4: Channel 1\n",
    "    x1 = Convolution2D(384, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_4_x')(x1)\n",
    "\n",
    "    # Convolution Layer 4: Channel 2\n",
    "    y1 = Convolution2D(384, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_4_y')(y1)\n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 4 channel 1\n",
    "    x1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(x1)\n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 4 channel 2\n",
    "    y1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(y1)\n",
    "    \n",
    "    ####### LAYER 5 ###################\n",
    "    # Convolution Layer 5: Channel 1\n",
    "    x1 = Convolution2D(256, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_5_x')(x1)\n",
    "\n",
    "    # Convolution Layer 5: Channel 2\n",
    "    y1 = Convolution2D(256, 3, 3, subsample = (1, 1), \n",
    "                  init = 'he_normal', \n",
    "                  border_mode = 'valid', \n",
    "                  activation = 'relu', \n",
    "                  name = 'conv_5_y')(y1)\n",
    "    \n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 5 channel 1\n",
    "    x1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(x1)\n",
    "    \n",
    "    # Zero Padding (1, 1) on Layer 5 channel 2\n",
    "    y1 = ZeroPadding2D(padding = (1, 1), dim_ordering=DIM_ORDERING)(y1)\n",
    "    \n",
    "    \n",
    "    # Pool Layer 5\n",
    "    # Max Pooling Layer 5: Channel 1\n",
    "    x1 = MaxPooling2D((3, 3), strides = (2, 2), dim_ordering=DIM_ORDERING )(x1)\n",
    "    \n",
    "    # Max Pooling Layer 5: Channel 2\n",
    "    y1 = MaxPooling2D((3, 3), strides = (2, 2), dim_ordering=DIM_ORDERING)(y1)\n",
    "    \n",
    "    # reduce from 4 dimensions (?, 6, 6, 256) -> (?, 43264) so its FLAT\n",
    "    x2 = Convolution2D(9216, 6, 6, init = \"he_normal\", border_mode = 'valid', activation = 'relu')(x1)\n",
    "    x2 = tf.reshape(x2, [-1, 9216], name = 'flattened')\n",
    "    \n",
    "    y2 = Convolution2D(9216, 6, 6, init = \"he_normal\", border_mode = 'valid', activation = 'relu')(y1)\n",
    "    y2 = tf.reshape(y2, [-1, 9216], name = 'flattened')\n",
    "    \n",
    "    # TODO: Maybe add a relu after these layers\n",
    "    ###### Fully Connected 1 using Xaviers algorithm (glorot normal) ########\n",
    "    x3 = Dense(4096, activation = 'relu', init = 'glorot_normal', name = 'fc1_x2')(x2)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "    \n",
    "    y3 = Dense(4096, activation = 'relu', init = 'glorot_normal', name = 'fc1_y2')(y2)\n",
    "    y3 = Dropout(0.5)(y3)\n",
    "    \n",
    "    ###### Fully Connected 2 ########\n",
    "    x3 = Dense(4096, activation = 'relu', init = 'glorot_normal', name = 'fc2_x2')(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "    \n",
    "    y3 = Dense(4096, activation = 'relu', init = 'glorot_normal', name = 'fc2_y2')(y3)\n",
    "    y3 = Dropout(0.5)(y3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Merge ####### \n",
    "    # TODO: Try concatenation instead of merging\n",
    "    m3 = merge([x3, y3], mode='concat', concat_axis = 1, name = 'merge_x3y3')\n",
    "        \n",
    "    #### Fully connected 3 ######\n",
    "    fc3 = Dense(8192, activation = 'relu', init = 'glorot_normal', name = 'fc3')(m3)\n",
    "    \n",
    "    ### Fully connected 4 ######\n",
    "    fc4 = Dense(1024, activation = 'relu', init = 'glorot_normal', name = 'fc4')(fc3)\n",
    "    \n",
    "    ### Fully connected 5 ######\n",
    "    prediction = Dense(1, name = 'output')(fc4)\n",
    "    \n",
    "    OUTPUT = Lambda(lambda x: x)(prediction)\n",
    "    \n",
    "    print('prediction: ', type(prediction))\n",
    "    print('prediction shape: ', prediction.get_shape)\n",
    "    \n",
    "    model = Model(input = inputImg, output = OUTPUT)\n",
    "    \n",
    "    # maybe make adam optimizer beta = 0.75\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually create testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_size:  918\n"
     ]
    }
   ],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "prediction:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "prediction shape:  <bound method Tensor.get_shape of <tf.Tensor 'add_18:0' shape=(?, 1) dtype=float32>>\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Output tensors to a Model must be Keras tensors. Found: Tensor(\"add_18:0\", shape=(?, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-740ec20a76b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepVo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     history = model.fit_generator(\n",
      "\u001b[0;32m<ipython-input-14-7ccd65050252>\u001b[0m in \u001b[0;36mDeepVo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# maybe make adam optimizer beta = 0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jj/anaconda2/envs/python3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input, output, name)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                 raise Exception('Output tensors to a ' + cls_name + ' must be '\n\u001b[0;32m-> 1661\u001b[0;31m                                 'Keras tensors. Found: ' + str(x))\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0;31m# build self.output_layers:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Output tensors to a Model must be Keras tensors. Found: Tensor(\"add_18:0\", shape=(?, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = DeepVo()\n",
    "train_size = len(train_data.index)\n",
    "for i in range(3):\n",
    "    train_generator = generate_training_data(train_data, BATCH)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n",
    "    \n",
    "    model.save_weights('model-weights-F1.h5')\n",
    "    model.save('model-F1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = DeepVo()\n",
    "print('model created!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python - FAISS",
   "language": "python",
   "name": "faiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

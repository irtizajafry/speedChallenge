{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jonathan Mitchell\n",
    "### 03/31/17\n",
    "### Speed test challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dataframe with image_path, time(seconds) and speed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# * In the video given, we have ~344 (5min 44s) seconds of video. \n",
    "* Our ground truth labels correspond to a video that is 12m 12s (~732seconds). \n",
    "* We only have a portion of that video. \n",
    "* It appears that our framerate <strong>~ 11.7552 fps </strong>. (8616 frames * (1 second / 13frames) = 344 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9839"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logs = read\n",
    "# newlogs = logs[['Time','Speed']]\n",
    "# from datetime import datetime, timedelta\n",
    "# def GetTime(sec_v):\n",
    "#     sec = timedelta(seconds=int(sec_v))\n",
    "#     d = datetime(2019,2,1) + sec\n",
    "#     return d\n",
    "# newlogs['NewTime'] = newlogs['Time'].apply(GetTime)\n",
    "# upsampled = newlogs.resample('S')\n",
    "# newlogs.set_index('NewTime',inplace=True)\n",
    "# upsampled = newlogs.resample('S')\n",
    "# interpolated = upsampled.interpolate(method='linear')\n",
    "\n",
    "# print (interpolated)\n",
    "\n",
    "df = pd.read_csv('./test_suite/data/m1.csv')\n",
    "df.head(10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plot Speeds vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmUFPW1x7+XVZBNhmGdgUEYRMARdRBGERUFRElQo0bjQqLiE/Wp0ZyEF/ISPU9fQvISjYaooEZ8RhFRA7IqRuLG4qA4bMIgMIDMhuzIMsB9f9z6va6Z6aW6u6q7q+Z+zulT3bV03enu+dat+7v3/oiZoSiKovifRuk2QFEURXEHFXRFUZSAoIKuKIoSEFTQFUVRAoIKuqIoSkBQQVcURQkIKuhK4CGiJUR0ZxrPv4CIxqXr/ErDQQVd8QwiGkpEnxLRPiLaTUSfENGgdNvlJkR0EREdtB6HiIhtrw8SUXdmHs3M09NtqxJ8mqTbACWYEFEbAHMBTAAwE0AzABcBOJpOu9yGmT8C0AoAiCgPwBYA7Zj5eBrNUhoo6qErXtEHAJj5NWY+wcyHmfldZi4BACL6seWxP2158F8R0WXmYCJqS0QvEFE5EX1DRI8RUWPb9tuJaD0R7SGiRUTUw7ZthPV++4joLwAonIFE1JWIDhNRe9u6c4hoFxE1JaLeRPQv6312EdHriXwQ9pCP7e9+goj2EtFmIrrAWr+diKrs4Rkiak5E/0NE24iokoieJaIWidihBB8VdMUrNgI4QUTTiWg0EZ0WZp/BADYD6ADgNwDesonrdADHAfQGcA6AkQCMKF4N4JcArgWQDeAjAK9Z2zoAeBPAr6z3/RrAheEMZOadAJYC+IFt9Y8AzGLmGgD/BeBdAKcByAHwdNyfQngGAygBkAXgVQAzAAyy/tZbAPyFiFpZ+06GXBwHWtu7Afi1S3YoQYOZ9aEPTx4AzgTwEoAdEHGeA6CTte3HAHYCINv+KwDcCqATJDTTwrbtJgAfWM8XALjDtq0RgO8A9ABwG4Bltm1knf/OCDbeCeCftn23AxhmvX4ZwFQAOQ7/3jwADKBJnfVLzPmtv7vUtu0s65hOtnXfQgScABwC0Mu2rQjAlnR/t/rIzId66IpnMPN6Zv4xM+cAGACgK4Anbbt8w8z27nBl1j49ADQFUG6FJfYCeA5AR2u/HgD+bNu2GyJ+3azjt9tsYPvrMMwCUEREXQEMg4jrR9a2n1vvu4KI1hLR7XF/COGptD0/bNlZd10ryN1HSwArbX/rQmu9otRDB0WVlMDMXxHRSwD+zba6GxGRTdS7Q7z47RAPvQOHH1zcDuBxZv573Q1ElA8g1/aa7K/D2LWXiN4FcAPkjuI1Yw8zVwAYb73PUACLiehDZt7k8M9Oll0Qce/PzN+k6JyKj1EPXfEEIupLRA8TUY71OhcSNllm260jgPutAcjrIYI6n5nLIbHrPxJRGyJqRES9iOhi67hnAfwHEfW33rutdTwAzAPQn4iuJaImAO4H0DmGua9CQjU/sJ6bv+F6Yz+APRDv/UQCH0dCMPNJANMAPEFEHS2buhHRqFTZoPgLFXTFKw5ABv+WE9EhiJCvAfCwbZ/lAPIhnujjAK5j5m+tbbdBUh3XQcR0FoAuAMDMb0MGC2cQ0X7rfUdb23YBuB7A7yCx6HwAn8SwdY61XyUzf2lbP8iy/6C1zwPMvCW+jyFpfgFgE4Bl1t+6GMAZKbZB8QlUO4SpKKmBiH4MGSgcmm5bFCUoqIeuKIoSEFTQFUVRAoKGXBRFUQKCeuiKoigBIaV56B06dOC8vLxUnlJRFMX3rFy5chczxywoS6mg5+Xlobi4OJWnVBRF8T1EVOZkPw25KIqiBAQVdEVRlICggq4oihIQVNAVRVECggq6oihKQFBBVxRFCQgq6IqiKAFBBb0hwQxMmwZUV6fbEkVRPMCRoBNROyKaZc2kvp6IioioPRG9R0Sl1jLcJMBKJrFuHXDXXUBuLnDkSLqtURTFZZx66H8GsJCZ+wI4G8B6ABMBvM/M+QDet14rmcwWa26Go0eB8ePFY1cUJTDEFHQiagOZPPcFAGDmY8y8F8BYANOt3aYDuNorIxWX2LpVlvfeC7zyCjB5clrNURTFXZx46KcDqAbwNyL6goieJ6JTAXSy5n6EtewY7mAiuouIiomouFpjt+mlrAw45RTgqaeAG28EfvlLoLQ03VYpiuISTgS9CYBzATzDzOcAOIQ4wivMPJWZC5m5MDs7ZrMwxUvKyoDu3YFGjYDf/EZCLp/Emm5TURS/4ETQdwDYwczLrdezIAJfSURdAMBaVnljouIaW7cCpn1xnz5AmzbAihXptEhRFBeJKejMXAFgOxGZmcYvg8zEPgfAOGvdOACzPbFQcY+yMqBHD3neqBFw3nnAZ5+l1yZFUVzDaT/0fwfwdyJqBmAzgJ9ALgYziegOANsAXO+NiYorfPcdUFUVEnQAGDQIeOIJyXpp3jx9timK4gqOBJ2ZVwEoDLPpMnfNUTxj2zZZ2meMGjQIqKkBSkrkuaIovkYrRYPEJ59IfvnJk/W3mZRFu4d+/vmy1LCLogQCFfQgcfvtwPPPA59/Xn9bmTWDld1Dz80FOnbUgVFFCQgq6EGio1UKMG9e/W1lZUCTJkCXLqF1RBJqUQ9dUQKBCnqQOHRIlnPn1t+2dat45I0b114/aBCwfj1w4IDn5imK4i0q6EHCxMmLi4Hy8trbyspqh1sMgwZJgVG4MI2iKL5CBT0o7N8P7NkD3HKLvJ4/v/b2rVtrD4gaTHaLxtEVxfeooAcFM+g5ZoyU99vDLseOiccezkPPzpb1GkdXFN+jgh4U7FksY8YA770X6nm+fbuEVcJ56IAOjCpKQFBBDwr2PPMxY2SA9F//qr0tnIcOiKBv3aozGSmKz1FBDwqmNW6nTsCllwItW4bCLsZ7j+ahAzKYqiiKb1FBDwqmNS6RCPvllwNvvy2DpVu3SjOunJzwx557rixXrUqZuYqiuI8KelCom8Xy0ENARQXwwx8CX38NdOsGNG0a/tg2bSQcU1KSCksVRfEIp90WlUynrAwYODD0+uKLgWeekUmhGzUCLrgg+vEFBSroiuJz1EMPAuFa4wLSqOsXv5BmXZEGRA0FBcCGDaHMGEVRfId66EEgXGtcw3//t8TUL700+nsUFAAnTkgbgHPOcd1ERVG8RwU9CIRrjWto1Ah45JHY71FQIMuSEhV0RfEpGnIJAuFa48ZL797iyYeLox87BkyeHGr+pShKRqKCHgS2bq3fGjdeGjcG+vcPL+gzZgATJwKPPZb4+yuK4jkq6EGgrCx8a9x4iZTpUlEhy02bknt/RVE8RQU9CJSVRa4CjYeCAsmWqaysvX7dOllu2JD8ORRF8QwV9CCwc6cUDiWLfWDUzpo1oeX+/cmfR1EUT1BB9zvM0hq3a9fk3+uss2RpF/QTJ8RD799fzqV90xUlY1FB9zt79gBHjyY3IGrIzpb3sQv6li3A4cPAHXdIn5ilS5M/j6IonqCC7nfMVHNuCDpQf2DUhFsuvBDo108FXVEyGEeCTkRbiWg1Ea0iomJrXXsieo+ISq3lad6aqoTFC0Fft068ciAk6P36AUOGAMuWSSsBRVEyjng89EuZeSAzF1qvJwJ4n5nzAbxvvVZSzc6dsnQjhg5Ii4Bjx4APP5TXa9YAPXsCrVoBRUUS4tm40Z1zKYriKsmEXMYCmG49nw7g6uTNaQCcPAncey/w+OPuvJ/bHvoll0jF6IIF8nrNGmDAAHleVCRLDbsoSkbiVNAZwLtEtJKI7rLWdWLmcgCwlh3DHUhEdxFRMREVV+sUZ8CvfgX89a/S2tYNysvFe27Vyp33a9FCRH3+fPHUN2wICXrfvkC7diroipKhOBX0C5n5XACjAdxLRMOcnoCZpzJzITMXZmdnJ2RkYHjhBeC3v5WZhb75RiZvTha3UhbtXHklUFoqXvrx4yFBb9QIGDxYBV1RMhRHgs7MO61lFYC3AZwPoJKIugCAtazyyshAsHw5cPfdwMiRwOuvyzo3hHHnTvfCLYbRo2X5hz/I0gg6IGGXtWu1wCgax49L22IzvqEoKSKmoBPRqUTU2jwHMBLAGgBzAIyzdhsHYLZXRgaCGTOkgdbMmcB550loww1BLy93X9B795bHJ59If5gzzghtKyqSAqOPPnL3nEHi7beBSZOAN95ItyVKA8OJh94JwMdE9CWAFQDmMfNCAL8DMIKISgGMsF4rkfj0U2DQIKBtW5nbs7AweUE3VaJuCzoQ8tJzc4HmzUPrL74YyMoCXnrJ/XMGhaeekqUZsFaUFBFT0Jl5MzOfbT36M/Pj1vpvmfkyZs63lru9N9enHDkCfPFFKEsEkOeff57clG/798v0c27H0AGJowPAt9/WXt+8OXDbbcDs2dLIS6nN558DH38sz1XQlRSjlaKpYOVKoKamvqDX1IgAJIrbKYt2Lr5Ylg88UH/b+PFi+/Tp9bc1dJ5+GmjZUjKCNIaupBgV9FRgQit1Bd2+LRG8FPQWLcT7f/TR+tvOPFNaATz/vIR9FKG6GnjtNWDcOBF09dCVFKOCngo+/RQ4/XSgU6fQuk6dpAIzGUE3HqAXgg6IqDeK8BMZP14qRk1FaSZy/Lj0ii8vlwpXry8+06ZJo7T77pMwmAp6YuhUhwmjgu41zCLadu/cUFQk2xIVGiMYXsTQY3H99TLA+/zzqT+3UyZMkHlWu3YF2reXafS8ZM4c+U779ZOL7O7dyY2RNEQ+/1yK5ObPT7clvkQF3WvKymQKt0iCvnNn4gVG5eXiRbdpk5yNidCyJXDzzcCsWeL9ZhonTgBvvQUMHy5VuZddBkyZAuzd6835jhwRMbroInlt7prM9H2KM95/X5Z/+1t67fApKuheY0IqF1xQf5sR+U8/Tey9TcoiUWLHJ8v48SJkr7ySnvNHY9ky8ZDvvlse//M/cis/bZo35/v889oD3+auScMu8fHll7Jcuza9dvgUFXSv+fRT4NRTQ7MB2SkoSK7AaOfO9IRbDAMHSpHUtGmZNzg6d64Uco0cKa8HDhRv/amnRHjdpu7At/HQG6qg790LjBgRavLmlOXLZbl+vTutMRoYKuhes3y5FBE1aVJ/W9Om4rnPn59Yj3GvioriYfx4YPXqzJuabu5cYNgwifMbHnoI2LFDwkRus3SpDHKbgW/zvTTU1MV584DFi6Wewam3/e23wKZNwC23yOt33/XOvoCigu4lJ05I+9lzzom8z+23y4948eL43z8TBP2mmySe7lUoIxG2bpXPfcyY2utHj5Y2Bn/6k7t3FMxyJ2YfJ8nOlrYJDdVDN555p07A979fv0AtHMYpuP12mfR80SLv7AsoKuhesnmzzPwTLtxi+MEP5J9/ypT43vvgQeDAgfQLeps2wI03Sq+aAwfSa4th3jxZXnVV7fWNGgE//SlQXOxuL5pt20S47YLeqBHQuXPDFPQTJ0SMb7lFKoq/+Qa47rrYoa7ly2U8qLBQQmWLF8t7KY5RQfcSMzdnQUHkfZo3l7DF3LmSEeOUdKYs1mX8eBlwnDEj3ZYI8+YB+flAnz71t916q3iNd98N7NvnzvnCFY4BcrFtiIJeXAzs2iV3RIMHA889ByxZArz8cvTjli8H+vcHWrcWQd+zR95LcYwKupesXi0eR79+0ff7t3+T5XPPOX9vL6tE42XwYGmxmwlhl0OHgH/+s364xdCypVx4Sksl7dIND3DpUhncrnvh7tKlYcbQFyyQ3/2oUfL6ttvkLvXppyOHupgl5DJ4sLweMULeQ8MucaGC7iUlJeIptmwZfb/u3SXO+PzzUmnohEwSdCLx0j/7LJR2li4WLZLPMJKgAzIj01NPiSc/aVLy51y6VDppNm1ae31DrRZdsECEOStLXhMB998vvw17qKukBPjqK3n+9deSZmoEPStLQi8q6HGhgu4lq1dHD7fYmTBBeoEsXOhsf7cnh06WW26R8FE6G3aVl4tw5OUBQ4dG33fCBLkzmjw5FBpLhMOH63fSNHTpIt+pF2mSmUp1tVzYTftlw49+JNW6prVwcTFw9tnSF2j9+lC6ohF0QDz85cu9KwYLICroXnHokHgd0QZE7Zx/vixLS53tX14uAnraaYnZ5zbt20tO+qpV6Tn/kSPANdfIP//s2UCzZrGPeeQRWSZTZr5ypfSMiSToQMOqFl20SMIndQW9ZUu5i3v7bWkv/L3vhbZddZWMIZ16qsTQDcOHS0hs2bLU2B4AVNC9Yu1a+WE79dDbtZOc6a1bne1fXi5ZFOmqEg1Hnz7SsCvVMMsg5/LlMvDm9DPv3Fm8xHjznZnlwrt2rQgREF7QG0q1aE2N3OUsXSrdJrOz5eJel3vukXqLiy6SO5u1a0Wsy8tlXKOwUFI9DWefLcvVq1PzdwQAFXSvMLfxTj10AOjRw3mmixdziSZLnz6SonbwYGrPW1wsoZ7//E/g2mvjO3bkSPEY47F51iz5WwcMkJBNfj7QsWP9/RpKtejDD4v4miK5MWPCd+ns3j3kuc+aJckCgweHWkfUbY/Rvj2Qk5NcSKyBEaZ8UXGF1avlFrJnT+fH5OUBW7Y427e8XOKPmYRJEywtjV5M5TbvvCMC8uCD8R87apRMhr1kSfSBVDvvvy/596bTZKQ7goYi6MuWiUf++OMSWjn33Mj7vv66VOvaf7s/+IFclPPz6+9fUKCCHgfqoXtFSYl4cJH6iYejRw8JuTipYsyEKtG6GEFPddhl7lyZcKN9+/iPHTpUUg7jyaZYuhQYMkRaCF9/fe1JtO107CghsSCnLppq6IsukovjRReJIxOJ1q3DOyLnnRe+a+hZZ8mgaUMaWE4CFXQvYI4vw8WQlyfVlrFG9XfskH1ycxM20RN695ZlKgV9xw7JMnHqXdeleXNJY3QaRz9wQAQsXMy8Lk2aSBGTHz30e++V1MGsLPkbIjXZMtXQ8f7WnVJQIGK+YYM37x8wVNC9oLxcelfE+yPv0UOWsQZGp00Tz+/66xMyzzNatJA4aSoF3ZT5JyrogHiWGzc6G5BesUIG9pwIOuDPatHNm6WHfEGBpBsePiy95cORyFhRPJj/IQ27OEIF3QsS/ZEbQY82MFpTI4J+xRUyrV2mkepMl7lzZZwimfEEU9HoJOxiyvzt+dLR8GO16F/+Itkmr7wi1Z0XXRS5xfPq1RJWjFUNnShnnCEFWyrojtBBUS8waVbxCnpeniyjCfrs2eLxTZ2akGme06cP8OqrEnaKllI5YwYwc6YIh3k0aSLx10cfldS3WHz3nTRwuuuu5NI3zzhDwleLFoXaMERi6VIRr3btnL13164y+YVfOHAAeOEF4IYbpOMhIOMFCxZI7xt7O2JAfuu9e8euhk6Upk3lYq2pi45wLOhE1BhAMYBvmHkMEfUEMANAewCfA7iVmY95Y6bPKCmRf4Z4B+mysuQfI9qt/1//Kp583cKNTKFPH4nv79oVWZTfeENu5XNyZP7IEyfkcfy4dC5s2xb47W9jn+uDD6SgKJlwCxDqOzJzptgQrnc9IBepZcukgMkpXboAVVXy99lzrDOVl14C9u8HHnggtK6oSP725ctDE4YYSkpk8hAvKSiQLCQlJvGEXB4AsN72ejKAJ5g5H8AeAHe4aZivSWRAFBBhycuL7KGvXy8idvfdmSsOsTJdliyRNgEXXCADXevWyXLTJrmQXX213H0cPhz7XO+8IxeEYcOSt3vUKBGyzz6LvM/GjdJvxGn8HBBBP3lSRD3TOXkS+POf5e8zlcuAPCeqH3aJtxo6UQoKZPB7925vzxMAHAk6EeUAuArA89ZrAjAcgJn6ZTqAq70w0HccPCgiZarc4sWkLoZj6lS5Bb399oTN85xogv7VV8DYsXKLPmeODKLW5f775R/31Vejn6emRsJPI0dKpkqymMmdP/kk8j5m7td4BN1Ui/ohjj5vngh03Xz+Nm0kBbduCX681dCJYt5fwy4xceqhPwng5wDMPGlZAPYy83Hr9Q4A3cIdSER3EVExERVXV1cnZawvWLJExGbEiMSOj1Yt+tln4tmGq0rMFHr0kItOOEF/5hng2DFpQBYpHHXxxbFbrQIi5hUVwE9+4o7dnTrJ4Gq0+V2XLpXYed++zt/XT8VFTz4pYwnhqm2LikTQ7VMlJjpWFC/m/VXQYxJT0IloDIAqZl5pXx1m17D/fcw8lZkLmbkw28lAl99ZuFAG9i68MLHj8/LEQw03+09lZeYVE9WlSROgV6/6gs4sIZLLL4+ePx+p1WpdvBhLKCoS0Y50IVm6VLJb4ikW84ugl5RIH/n77gs/hjBkiIyN2PPBS0rir4ZOhC5dZHxJM11i4uSXeSGA7xPRVsgg6HCIx96OiMw3nwPAB/eUKWDhQukSl2gYIFrqYmVlaBLiTCZc6uJXX0lbAycDmHVbrdbFq7GEoiIR3m3b6m+rrJSConjj9eb7ynRB//OfJQR2553ht5swk/0OZvXq+KuhE4FIWwA4JOY3wcz/wcw5zJwH4EYA/2TmmwF8AOA6a7dxAGZ7ZqVf2LRJYpBXXJH4e0RKXTx8WLz2TA63GPr0kX4u9ttz05Ww7jyf4bC3Wg0nrs88I+1x3R5LCCdahvfek6XJWXdKs2aS7fPNN8nZ5iXV1cDf/w6MGxc5FNanj7RqNp8Nswis1/FzQ0GBXFDtvymlHslcWn8B4CEi2gSJqb/gjkk+xkxOEe8/vZ1I1aImS8IvHvrRo8D27aF1c+dKeltOjrP3uOceWf71r7XXHzwonRWvv979i1tBgXip4QR90SKgQ4fEmo517x7+wpQpPPecfF/33x95n0aNJOxiBkYrKqQa2uv4ueHssyWrRlsARCUuQWfmJcw8xnq+mZnPZ+bezHw9MzucOy3ALFwoGRy9eiX+Hp06iVdX10OvrAxtz3TqZrrs3i3ZI/Hki3fvLvne06ZJAZHh1VclvdAIvps0bSpTydUV9JMnpdfLiBGJhRd69nTeRTPVHDsGTJkid5Wxqm2LiiSzZd++0ABlqjz0Sy6R5eLFqTmfT9HSf7c4ckTiusmEWwARjHCpi34UdJPTvWiRFNbEWwBUN4WxshL4r/8Sby2e1MF4KCqSZl/2PPiSErlDSvTOy9QWOOmimWo++ki87QkTYu87ZIj8DZ06hb7LVHnoPXtKe12dYzQqWvrvFh9/LJ5ksoIOhE9dNILuhxh6587ApZdKCf+wYRJuyc4W7zceLrpIxPupp6QY6Zpr5DZ/zhzvZmoqKpJq0ZUrQ/OSGhGpWyXplJ495YJfUZF5WUpmUm8nF8hLLwUee0w8dEDuRhNpWZwoI0cCf/ubhIfcqD0IICrobrFwoYRKzK1hMuTliWjZ8VMMnUhmpCkqEk9u3z7gxz+OP1xhUhjvuEPCAVu3Snm+l5Nn2AdG7YJ+1lmJi7FJ69uyJfMEvaRELsBOUoqbNAEmTfLepkiMGiXhoU8/lYuLUg8NubjFwoXijUZr7u+UHj1EwO23/ZWVUrF3yinJv38qaN9eKg+NN5dov5WbbpLl1q3Ar3/tfcvgjh2li+XHH8vrQ4fkeTID3SZzyel8sYYvvpCqzSNHEj93LBJtU5EOLrlELioadomICrobbN8ug0VuhFuAkADYMyP8koNup3dv8XR/8pPEP5sWLaSN689/DvzmN+7aF4nvf1/ukGbODFX+uiHo8Q6M3nmn5IePH+9N/P34cfnd+kXQW7eWgr14J/VuQKigu4HxGNwS9HCpi34UdEAG0l58Mbk7l5tvlsmYvS5gMfz2tyIct90GPPKIXFRM+CURWrSQ7y4eD331amm727q1XND+8IfEzx+J0lKJR6dqYNMNRo6UOxczpqTUQgXdDRYulPxqt5r8h6sWraryx4BoEDjlFOAf/5DvtLhY8ueTDXXFm7r49NNyIdiyBfjhD4GJE0PFWW5hKi/94qEDoTslTV8Miwp6stTUSBXhFVe4l3nRtavECoPgofuVDh2A+fMlXFK3+2Ai9Ozp3EP/9lvxym+5RXqYvPiiDATfdpvE9N1i9WppnZDMbE+p5pxz5LvROHpYVNCTZflyKXRxK9wCiJjn5IQ89Joa+SdXQU8tffrI/Jo33JD8e+XlyZjIiROx933hBRkQ//d/l9ctW0onxD17ZKYntygpkdma/JQC2KiRFHi9+25m5vWnGRX0ZFm4ULycyy5z933z8kIenWk7rIKeety66+rZUy7MsXq6MEuvmksuqR3bHjpUGmFNmeKekKWyF4ubDBsmd6zRpmpsoKigJ8vChZK77HSOSafYi4tMDrrG0P2L09TFkhLZ59Zba68nAu69VwYEly9P3p59++T35UdBNwVqK1ak144MRAU9GaqqpKLQzXCLoUcPmeXm2DF/lf0r4bEXF0XDDHxeeWX9bTffLFkvdRuWJcKaNbL0U4aL4ayzpIgv2nSBDRQV9GRwO13RTl6e3Fpv366CHgRyc8XLjuWhz50rHmjnzvW3tW4tA6Ovvy6TcCeDHzNcDM2aSeaRCno9VNCT4aWXpCugF6Xo9tRFFXT/07w50K1bdA+9qkrCKdGqau+5R+7aXnwxOXtKSoC2baPPHpXJDBokd8dOBpkbECroibJ+vUzZdffd3hS82GOuVVWSk9yqlfvnUVJHrNTFBQvkriyaoPfrJ2mG0eY+dYIZEPWqyZnXDBokvfG1P3otVNAT5dlnpX/2HXd48/45OfLPZjz0jh39+8+nCHl50T30uXOlBiHWHV9ubnIzIDFLDrof4+cGMzCqYZdaqKAnwqFDMmvOddd5l3nSrJn8cxtB13CL/+nZE9ixQ9IXASnnnzZNnh87JmMyY8bEvnDn5Mj7JEpxsUxn6GdBP+MMuWNVQa+Fts9NhNdek7QvL2bNsWNy0ffulVi94m/y8mT2o+3bRbR//nNZf+qp4hgcOOCsK2W3btJbvaZG7hLjobpaOlZ27Qpce23cf0LG0LgxcN55Kuh1UA89Xpglbeyss6SBk5eYXHT10IOBPXXRpB726iXdKCdOlH4xTgrUcnLkd1hREd/5jx2Tu8qKCulV4/e6hkGDgFWr5O9SAKigx8/q1VLccffd3se0Tbl4RYX///mUkKDH7/r/AAAV4klEQVSvXQs8/7x4yitWyPe8ciVQWChl/rHo1k2W9jj6oUPSMiBaFenEicCHH8p+8c4elYkMGiRibuY3dYpxyn71K3k89VRg2ghoyCVeTOFHKm5Xe/SQW3RAPfQg0K2bhAoee0zCaPffLxOBzJ8vPdh/9jNn75OTI0t7HH3SJOmdnpMTvnd7eTnwl79Ij/Wbb07+b8kE7AOj553n/LgPPpCq20aNRMiZgdGjZc5Sn6MeerxEK/xwG5OLDqigB4EmTSRDpbpaMllMyK5XL/Hax4519j7hPHSTPWPaRNRlyhSZ0OIXv0jM9kwkL08GRtevj++4J56QKfcOHpSLKZB8oVaGoIIeD9XVwLJliU+nFi8mFx1QQQ8KJg/9/vsTD9llZUmhkt1DNwU2mzfX3/+776Th19ixMotUUCCSC2Q8GT8bNohTds89UtuRlSXrv/3WGxtTjAp6PDgp/HATe2aLCnowuOYaWd54Y+LvQSReut1DN6K2aVP9/adPB3bvBh5+OPFzZirxpnA++aRcDCdMkNcNTdCJ6BQiWkFEXxLRWiJ61Frfk4iWE1EpEb1ORM28NzfNvPOOs8IPt2jRIvRcB0WDwSuvSFgk2RmQ7ELGHBLy0tLa+508KSGGQYO8z8pKB7m5kgbqhG+/lYvbLbeEHKSGJugAjgIYzsxnAxgI4AoiGgJgMoAnmDkfwB4AHpVMZgim8OOqq9JTsXnaaak/p+I+LVtK/DZZ7B56eXloJqO6gj53rqx76KFgVhrn5IRy8mPx3HMycchPfxpa16aNjG00FEFn4aD1sqn1YADDAcyy1k8HcLUnFmYKH33kvPDDC1I1QbLiD3JyRNDt3vnIkRJa2b07tN8bb8gF5Lrr0mOn1+Tmymewc2fsfWfOBC6+GOjfP7SOSDKNGoqgAwARNSaiVQCqALwH4GsAe5n5uLXLDgDdIhx7FxEVE1FxtZl5x4/MnSuxN7dnJorFpk3Axx+n9pxK5tOtG3D0qAiR8cpHj5alPY6+dKmEWpoENEM5XApnOE6eBDZuDJ/e2NAEnZlPMPNAADkAzgcQblbZsJn5zDyVmQuZuTDbjVvNdMAs8fPhw6VMO5X06hXM2KeSHHYhKy2VFgDG2TACX1UFfP21zKgVVEz731hx9B07JNzSp0/9bVlZgRH0uC7bzLyXiJYAGAKgHRE1sbz0HAAO7nl8wOTJcmtWUyOPY8dkuX27xCEVJROw56Jv2iRVqPn5EkIwHvqyZbIMsqA79dA3bpTlGWfU35aVFXviEZ8QU9CJKBtAjSXmLQBcDhkQ/QDAdQBmABgHYLaXhqaEp5+W8ujBg6Wop2nT0KN1a+BHP0q3hYoi1PXQ8/Mlc6Z795CHvnSphFoKC9Nnp9e0bSv/m7E8dNM3PZKHvnKl+7alASceehcA04moMSREM5OZ5xLROgAziOgxAF8AeMFDO73nH/8AHnhAii/efFNKtBUlU+ncWQbKd+wQj3z4cFnfu3dtQR84sHb6axBxkou+caOES7t0qb+tIYVcmLkEQL3Ea2beDImn+4fDh4GpU4Gbbqqd171smaw7/3zg1VdVzJXMp0kTEfXiYqkENRWg+fkSMjx+XHqceDUBSybhJBd940bxzsOlbmZlAUeOyOfopDlaBtNwcuFOnpQJdh98ULIBvvtO1m/aBHzvexKTfOcd33+hSgOiWzdgyRJ5bhpL5edL2uKSJfIbD3L83ODEQ9+wIXz8HAhUcVHDEfRf/hKYNQsYNkza3956q/QZv+IK2b5ggTsFH4qSKnJyxLMEQh66Wb78siwbgqDn5kpxUaS+6EePyqBnuPg5oILuO15+WbJXJkwQz+WPfwTeektuWb/5BpgzJxCtM5UGhsl0ado01PfH/I7/938lXmzv2BlUzIQf5eXht3/9tWxXQQ8Au3dLqe+wYdLInkjCLqYf8quvNgwvRgkeJtOlY8dQ4dDpp4fixEVFwSz3r4vJRY8UdomW4QKooPuKX/9a5v+cMiX0oyeSFMWKilD3O0XxG8ZDt4/7NG8uD6DhOCrmwhZpYNTkoKug+5ySEukDfc89wIABtbcRacxc8TdG0OumJZq4ekMR9Fge+saN0l2xbdvw21XQfQCzTCJw2mnAo4+m2xpFcR+Telu3cKhfP1mee25q7UkXbdpELy4yKYuRaNZMZj4KgKAHtGMPpMvcv/4FPPustp5Vgkn//tI0zhQVGRYvloHAoBcU2Yk2c9GGDbGn9wtIcVEwBf3QIZlwd+BAmRRXUYLKVVfVX9elS/iKyCCTkxPeQ9+zR6aOjOahA4ER9GCGXCZPli/36ae16lNRGgKRPPRYA6KGZAR92jRJvsgAgifoW7YAv/+9NNIaOjTd1iiKkgrMzEV1i4vWrpWlGVeIRFZW7YlBnMIM/O53wEsvxX+sBwRP0H/2M/HKJ09OtyWKoqQKM3NR3eKideskjfP006Mfn6iHXloKbN4sYR0OOyVESgmWoH/0kVSATpoUyk1VFCX4RMpFX7sW6Ns3dug1K0vi7SdOxHfe+fNlaZp7pZlgCfrSpbK899702qEoSmqJlIu+dm3tOUQjkZUlHvbevfGdd8GC0PMMmGIzWIJeUSFVc5EKCBRFCSbGQ9+2LbRu/37x2J0Ievv2sown7HLokKRGm/45KuguU1kpDbcURWlYtGkj1aBffRVat369LGMNiALOqkWZgQ8/lF7zAPDBB9LJ8bbb5LUKustUVMiXqihKw2PAAGDNmtDrdetk6TTkAkQX9KVLgYsvBq69VsR9wQKZBcn0g9q1KzG7XSRYgl5ZqYKuKA2VAQMkZn7ypLxeu9ZZhgvgTNBNOOedd4Ann5QB0csuC4V71EN3mYoKDbkoSkNlwADJNNm6VV47zXABnAm6SYkcPhx46CE5z+jREu5p2lQF3VVqauTLUA9dURompqOqCbusW+cs3AJIIkXjxtEFvaJCPP533gldAEaPls6tHTqooLuK+TDVQ1eUhokZ/FyzBjhwQEIkTgZEARHl9u1jC3rnzpJJ9/XXElM3M0JlZ2sM3VUqKmSpHrqiNEzatBGBXbMmlOHi1EMHYleLlpeHHMa2bYEhQ0Lb1EN3mcpKWaqHrigNF5PpYnq4uCno0cbosrP9IehElEtEHxDReiJaS0QPWOvbE9F7RFRqLdPbdFw9dEVRBgyQXPRVq5xnuBiceOiR2hL7KORyHMDDzHwmgCEA7iWifgAmAnifmfMBvG+9Th/GQ1dBV5SGy4ABkiAxe7bzDBdDNEGvqRHBjuah790r+6WRmILOzOXM/Ln1/ACA9QC6ARgLYLq123QAV3tlpCMqKmQaqVNPTasZiqKkEZPpUlYWX7gFiC7oxmGM5KF36CDLNHvpccXQiSgPwDkAlgPoxMzlgIg+gI4RjrmLiIqJqLjayxiTlv0ritK3b+i50wwXQ1ZW5K6JJqQbzUMH0h5HdyzoRNQKwJsAHmTm/U6PY+apzFzIzIXZ5o/2Ai37VxTllFNCzxPx0IHwXroR9GgxdMAfHjoRNYWI+d+Z+S1rdSURdbG2dwFQ5Y2JDlEPXVEUO4l46EB4QTdVopE0xoRcMt1DJyIC8AKA9cz8J9umOQDGWc/HAZjtvnlxoB66oigA8PDDsownwwVw5qFH0hgfhVwuBHArgOFEtMp6XAngdwBGEFEpgBHW6/Rw7JjMNqKCrijK738vbW2bNInvOCPo4cIm5eWyvVmz+I9NITH/Ymb+GABF2HyZu+YkSJUV7dGQi6IojRpFFt5oGIfQZLTYidX4r0kTaR3gAw8989GiIkVRkiUrS4TZ6ImdaEVFhgwo/w+GoGvZv6IoydKokTiF4QTdSWvuDCj/D4agq4euKIobdO4cymgxMIvGxPLQM6D8PxiCrmX/iqK4QZcu9T30ffuk4CiWh64hF5eoqJDWmS1apNsSRVH8TDgPPVZRkcF46GYKvDQQDEHXoiJFUdygSxfxsk+cCK2LVVRkyM6W4/bt886+GARD0LWoSFEUN+jcWTzsKlvhezweOpDWsEswBF09dEVR3MCItj2O7tRDz4Dy/2AIunroiqK4gRFtexzdTA7dtm30Y9VDd4EjRyRmpR66oijJYnTE7qGblEWKVDBvkQEdF/0v6CbWpR66oijJEs5Dt08OHQ0NubiAFhUpiuIWLVpIaCWchx6Lli3loYKeBFr2ryiKm9QtLnLqoQNprxb1v6Crh64oipvYi4sqKqQ/es+ezo5Nc7Wo/wVdy/4VRXETu4f+7ruyvPxyZ8emuUGX/wW9ogJo107SihRFUZLFeOjMwMKF4iyefbazY1XQk0SLihRFcZPOnYHvvpN06HffBUaNkta6TtAYepJoUZGiKG5iMlrmzZP4+ahRzo/t2FEuBgcOeGNbDPwv6OqhK4riJkZPXnpJiolGjHB+bE6OLHfscN0sJwRD0NVDVxTFLYyHvngxUFgYqgB1ggp6Ehw+DOzfrx66oijuYdeTeMItAJCbK8vt292zJw78Leiasqgoitu0bx96fsUV8R3brZss1UNPAC0qUhTFbewZLYMHx3ds8+YyMJqpHjoRvUhEVUS0xrauPRG9R0Sl1vI0b82MgJb9K4riBRdeKIOhTZrEf2xubkZ76C8BqHvfMRHA+8ycD+B963XqUQ9dURQv+PjjUJVovOTmZq6HzswfAthdZ/VYANOt59MBXO2yXc4wHnrHjmk5vaIoSj1ycjJX0CPQiZnLAcBapkdRKypkAKNZs7ScXlEUpR65uZJ9t39/yk/t+aAoEd1FRMVEVFztdo8DLSpSFCXTSGMueqKCXklEXQDAWlZF2pGZpzJzITMXZseToO8ELftXFCXTMLnoPhL0OQDGWc/HAZjtjjlxolWiiqJkGmksLnKStvgagKUAziCiHUR0B4DfARhBRKUARlivUwuzXAHN7Y2iKEom0LWr9IBJg6DHTLJk5psibLrMZVvio7oaOHoU6N49rWYoiqLUolkziRz4KOSSfsrKZKmCrihKppGm1EX/Cvq2bbLs0SO9diiKotQlTdWi/hV09dAVRclU0lQt6l9B37YNaNUKOC09bWQURVEikpMjsxaluLjI34LevbuMJiuKomQSaUpd9K+gl5VpuEVRlMxEBT1Otm3TAVFFUTKTNJX/+1PQDx0Cdu1SD11RlMwkTcVF/hR08yGph64oSibStKk0DlQP3QEmB109dEVRMpU0pC76U9A1B11RlEwnNzfkfKYIfwr6tm0ykauZYVtRFCXT6NUL2LIFOHEiZaf0p6CXlYmYJzKBq6IoSirIzweOHUtp2MWfgm6KihRFUTKV3r1lWVqaslP6V9A1w0VRlEwmP1+WKuhROHFCbmHUQ1cUJZPp2hVo0QLYtCllp/SfoFdUAMePq4euKEpmQyRhF/XQo6Api4qi+IX8fPXQo6JFRYqi+IX8fGDz5pSlLqqgK4qieEXv3pK6mKICI/8JelkZ0K4d0KZNui1RFEWJjsl0SVHYxX+CrjnoiqL4hRTnovtP0MvKNMNFURR/0LUr0LKleuhh2bZNPhgVdEVR/ECKUxeTEnQiuoKINhDRJiKa6JZRYdm/H7jqKukzfM89np5KURTFNfwg6ETUGMAUAKMB9ANwExH1c8uwWhw/DtxwA/DVV8CbbwJnnunJaRRFUVwnhamLyXjo5wPYxMybmfkYgBkAxrpjlg1m4L77gEWLgGeeAS6/3PVTKIqieEbv3kBNTUpSF5MR9G4A7H0hd1jrakFEdxFRMREVV1dXJ3amvn2BX/4SuPPOxI5XFEVJF0OHAo89JoOjHpNMQ3EKs47rrWCeCmAqABQWFtbbHvssBDz4YNyHKYqiZAR9+wKTJqXkVMl46DsA5Npe5wDYmZw5iqIoSqIkI+ifAcgnop5E1AzAjQDmuGOWoiiKEi8Jh1yY+TgR3QdgEYDGAF5k5rWuWaYoiqLERVKTcjLzfADzXbJFURRFSQJ/VYoqiqIoEVFBVxRFCQgq6IqiKAFBBV1RFCUgEHP8tT4Jn4yoGkBZgod3ALDLRXNShV/tBvxru1/tBvxru9rtLT2YOTvWTikV9GQgomJmLky3HfHiV7sB/9ruV7sB/9qudmcGGnJRFEUJCCroiqIoAcFPgj413QYkiF/tBvxru1/tBvxru9qdAfgmhq4oiqJEx08euqIoihIFFXRFUZSA4AtBT+lk1ElCRFuJaDURrSKiYmtdeyJ6j4hKreVp6bYTAIjoRSKqIqI1tnVhbSXhKes7KCGiczPM7keI6Bvrc19FRFfatv2HZfcGIhqVHqsBIsolog+IaD0RrSWiB6z1Gf2ZR7HbD5/5KUS0goi+tGx/1Frfk4iWW5/561YLcBBRc+v1Jmt7XrpsTwhmzugHpDXv1wBOB9AMwJcA+qXbrij2bgXQoc663wOYaD2fCGByuu20bBkG4FwAa2LZCuBKAAsgM1UNAbA8w+x+BMDPwuzbz/rNNAfQ0/otNU6T3V0AnGs9bw1go2VfRn/mUez2w2dOAFpZz5sCWG59ljMB3GitfxbABOv5PQCetZ7fCOD1dNid6MMPHnpqJqP2lrEAplvPpwO4Oo22/D/M/CGA3XVWR7J1LICXWVgGoB0RdUmNpbWJYHckxgKYwcxHmXkLgE2Q31TKYeZyZv7cen4AwHrIPLwZ/ZlHsTsSmfSZMzMftF42tR4MYDiAWdb6up+5+S5mAbiMiMJNt5mR+EHQHU1GnUEwgHeJaCUR3WWt68TM5YD8cwDomDbrYhPJVj98D/dZoYkXbWGtjLTbupU/B+Ix+uYzr2M34IPPnIgaE9EqAFUA3oPcMexl5uNh7Pt/263t+wBkpdbixPGDoDuajDqDuJCZzwUwGsC9RDQs3Qa5RKZ/D88A6AVgIIByAH+01mec3UTUCsCbAB5k5v3Rdg2zLm22h7HbF585M59g5oGQeY/PB3BmuN2sZUbZHi9+EHRfTUbNzDutZRWAtyE/oEpzq2wtq9JnYUwi2ZrR3wMzV1r/uCcBTEPoFj+j7CaiphBR/Dszv2WtzvjPPJzdfvnMDcy8F8ASSAy9HRGZGdvs9v2/7db2tnAe3ks7fhB030xGTUSnElFr8xzASABrIPaOs3YbB2B2eix0RCRb5wC4zcq8GAJgnwkTZAJ1YsvXQD53QOy+0cpe6AkgH8CKVNsHSNYKgBcArGfmP9k2ZfRnHslun3zm2UTUznreAsDlkDGADwBcZ+1W9zM338V1AP7J1gipL0j3qKyTB2S0fyMk9jUp3fZEsfN0yOj+lwDWGlshMbj3AZRay/bpttWy6zXIrXINxDO5I5KtkFvRKdZ3sBpAYYbZ/b+WXSWQf8outv0nWXZvADA6jXYPhdy+lwBYZT2uzPTPPIrdfvjMCwB8Ydm4BsCvrfWnQy4ymwC8AaC5tf4U6/Uma/vp6bI9kYeW/iuKogQEP4RcFEVRFAeooCuKogQEFXRFUZSAoIKuKIoSEFTQFUVRAoIKuqIoSkBQQVcURQkI/wdECbcgjDkEagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.asarray(df['time'], dtype = np.float32)\n",
    "speeds = np.asarray(df['speed'], dtype=np.float32)\n",
    "plt.plot(times, speeds, 'r-')\n",
    "plt.title('Speed vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>./test_suite/data/IMGm1/327.8333333333785.jpg</td>\n",
       "      <td>327.833333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9835</th>\n",
       "      <td>./test_suite/data/IMGm1/327.86666666671186.jpg</td>\n",
       "      <td>327.866667</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9836</th>\n",
       "      <td>./test_suite/data/IMGm1/327.9000000000452.jpg</td>\n",
       "      <td>327.900000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>./test_suite/data/IMGm1/327.9333333333786.jpg</td>\n",
       "      <td>327.933333</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>./test_suite/data/IMGm1/327.96666666671194.jpg</td>\n",
       "      <td>327.966667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path        time     speed\n",
       "9834   ./test_suite/data/IMGm1/327.8333333333785.jpg  327.833333  0.333333\n",
       "9835  ./test_suite/data/IMGm1/327.86666666671186.jpg  327.866667  0.266667\n",
       "9836   ./test_suite/data/IMGm1/327.9000000000452.jpg  327.900000  0.200000\n",
       "9837   ./test_suite/data/IMGm1/327.9333333333786.jpg  327.933333  0.133333\n",
       "9838  ./test_suite/data/IMGm1/327.96666666671194.jpg  327.966667  0.066667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Pairs and Train Test Split\n",
    "* This function is a batch shuffler, \n",
    "* There is a 20% chance to add the row to validation data, other wise it will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_shuffle(dframe):\n",
    "    \"\"\"\n",
    "    Randomly shuffle pairs of rows in the dataframe, separates train and validation data\n",
    "    generates a uniform random variable 0->9, gives 20% chance to append to valid data, otherwise train_data\n",
    "    return tuple (train_data, valid_data) dataframes\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(dframe) - 1):\n",
    "        idx1 = np.random.randint(len(dframe) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = dframe.iloc[[idx1]].reset_index()\n",
    "        row2 = dframe.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if 0 <= randInt <= 1:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        if randInt >= 2:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = batch_shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data:  4222\n",
      "train_data:  15454\n"
     ]
    }
   ],
   "source": [
    "print('valid_data: ', len(valid_data))\n",
    "print('train_data: ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5849</td>\n",
       "      <td>./test_suite/data/IMGm1/194.9999999999915.jpg</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5850</td>\n",
       "      <td>./test_suite/data/IMGm1/195.03333333332483.jpg</td>\n",
       "      <td>195.033333</td>\n",
       "      <td>32.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5538</td>\n",
       "      <td>./test_suite/data/IMGm1/184.63333333332542.jpg</td>\n",
       "      <td>184.633333</td>\n",
       "      <td>48.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5539</td>\n",
       "      <td>./test_suite/data/IMGm1/184.66666666665876.jpg</td>\n",
       "      <td>184.666667</td>\n",
       "      <td>48.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2484</td>\n",
       "      <td>./test_suite/data/IMGm1/82.8333333333312.jpg</td>\n",
       "      <td>82.833333</td>\n",
       "      <td>55.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                      image_path        time  \\\n",
       "0   5849   ./test_suite/data/IMGm1/194.9999999999915.jpg  195.000000   \n",
       "0   5850  ./test_suite/data/IMGm1/195.03333333332483.jpg  195.033333   \n",
       "0   5538  ./test_suite/data/IMGm1/184.63333333332542.jpg  184.633333   \n",
       "0   5539  ./test_suite/data/IMGm1/184.66666666665876.jpg  184.666667   \n",
       "0   2484    ./test_suite/data/IMGm1/82.8333333333312.jpg   82.833333   \n",
       "\n",
       "       speed  \n",
       "0  32.333333  \n",
       "0  32.355556  \n",
       "0  48.088889  \n",
       "0  48.111111  \n",
       "0  55.166667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(image, bright_factor):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow Dense\n",
    "* Two strategies\n",
    "* Strategy 1: get optical flow ang, magnitude, convert HSV to RGB and throw that image into the network\n",
    "* Strategy 2: get optical flow ang, magnitude, convert HSV to RGB then overlay ontop of original image and throw that into the network as RGB\n",
    "* Strategy 3: get optical flow parameters, ang, magnitude and expand dimensions of original image so you throw H x W x R x G x B x Ang x Magnitude into the network\n",
    "* Strategy 4: send in the flow differences as RGB (applied here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    gray_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    hsv = np.zeros((100, 400, 3))\n",
    "    # set saturation\n",
    "    hsv[:,:,1] = cv2.cvtColor(image_next, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    " \n",
    "    # Flow Parameters\n",
    "#     flow_mat = cv2.CV_32FC2\n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "        \n",
    "    # hue corresponds to direction\n",
    "    hsv[:,:,0] = ang * (180/ np.pi / 2)\n",
    "    \n",
    "    # value corresponds to magnitude\n",
    "    hsv[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # convert HSV to float32's\n",
    "    hsv = np.asarray(hsv, dtype= np.float32)\n",
    "    rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    return rgb_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand dims to add optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (220, 66, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             3) resize to (220, 66, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "    \n",
    "    image = cv2.resize(image_cropped, (400, 100), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# from IPython.display import Image\n",
    "# Image(filename=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(('./test_suite/data/IMG1/21.96447021964502.jpg')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# img1 = preprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, speed, bright_factor):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = change_brightness(img, bright_factor)    \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Generator\n",
    "* This is used to yield train batches of rgb_flow and average speed. \n",
    "* We pick a random spot in the training dataset, between 1 and length - 1\n",
    "* determine the relationship between 3 frames\n",
    "* locate the current_frame and the next_frame\n",
    "* Take the rgb_flow and the average speed and build batches with that information\n",
    "* Then shuffle the batch and yield it, which will then be fed into the network\n",
    "* Generators allow me to not clog my memory stack so I can perform these operations on 16 (`BATCH` size) at a time. Note: We process 32 images each time the generator runs. If we run 8 epochs and 20480 samples per epoch we are processing 8 x 20480 x 32 = 5.2M images total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 100, 400, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
    "            idx = np.random.randint(1, len(data) - 1)\n",
    "            \n",
    "            \n",
    "            # Generate a random bright factor to apply to both images\n",
    "            bright_factor = 0.2 + np.random.uniform()\n",
    "            \n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "                \n",
    "                # Use this to find outliers\n",
    "            else:\n",
    "                print('time_now is not next or prev: ', time_now)\n",
    "                print('time_prev is :', time_prev)\n",
    "                print('time_next is: ', time_next)\n",
    "                \n",
    "                print('\\n diff: now  - prev \\t', time_now - time_prev)\n",
    "                print('\\n diff: next - now: \\t', time_next - time_now)\n",
    "            \n",
    "            \n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
    "                                                row1['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
    "                                                row2['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "           \n",
    "            # compute optical flow send in images as RGB\n",
    "            rgb_diff = opticalFlowDense(x1, x2)\n",
    "                        \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = rgb_diff\n",
    "            label_batch[i] = y\n",
    "            \n",
    "        # Shuffle the pairs before they get fed into the network\n",
    "        yield shuffle(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Generator\n",
    "* This is used to yield validation rgb_flow and average speed. \n",
    "* We pick iterate through the validation data, determine the relationship between 3 frames, locate the current_frame and the next_frame. Take the rgb_flow and their average speed and feed that into the network\n",
    "* Reshape by adding an additional dimensions so the network perceives we are using a batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58:\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            img_diff = opticalFlowDense(x1, x2)\n",
    "            img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            yield img_diff, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Nvidia Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture changed as a result of added dimensions\n",
    "* I added extra filters to try to capture more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "N_img_height = 100\n",
    "N_img_width = 400\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides = (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides= (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_size:  4222\n"
     ]
    }
   ],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "filepath = 'model-weights-Vtest2.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.23,\n",
    "                              mode='min',)\n",
    "modelCheckpoint = ModelCheckpoint(filepath, \n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                 save_weights_only = True)\n",
    "callbacks_list = [modelCheckpoint, earlyStopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "400/400 [==============================] - 558s 1s/step - loss: 160.2011 - val_loss: 84.9720\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 84.97197, saving model to model-weights-Vtest2.h5\n",
      "Epoch 2/25\n",
      "400/400 [==============================] - 541s 1s/step - loss: 98.0725 - val_loss: 62.9615\n",
      "\n",
      "Epoch 00002: val_loss improved from 84.97197 to 62.96155, saving model to model-weights-Vtest2.h5\n",
      "Epoch 3/25\n",
      "400/400 [==============================] - 541s 1s/step - loss: 75.4982 - val_loss: 51.9619\n",
      "\n",
      "Epoch 00003: val_loss improved from 62.96155 to 51.96186, saving model to model-weights-Vtest2.h5\n",
      "Epoch 4/25\n",
      "400/400 [==============================] - 541s 1s/step - loss: 60.0253 - val_loss: 45.3954\n",
      "\n",
      "Epoch 00004: val_loss improved from 51.96186 to 45.39542, saving model to model-weights-Vtest2.h5\n",
      "Epoch 5/25\n",
      "400/400 [==============================] - 541s 1s/step - loss: 51.0158 - val_loss: 34.8535\n",
      "\n",
      "Epoch 00005: val_loss improved from 45.39542 to 34.85355, saving model to model-weights-Vtest2.h5\n",
      "Epoch 6/25\n",
      " 93/400 [=====>........................] - ETA: 4:06 - loss: 44.7703"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "train_generator = generate_training_data(train_data, BATCH)\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = 400, \n",
    "        epochs = 25,\n",
    "    callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = val_size)\n",
    "\n",
    "print(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model-v2test mean squared error loss 15 epochs')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow Approach MSE: ~5.5 for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2_loss = mpimg.imread('./model-vtest-2-loss.png')\n",
    "plt.imshow(model_v2_loss)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "* When passing the angle, and magnitude received from the optical flow calculation to the network my MSE is:\n",
    "* Method 1: Passing optical flow as RGB image only instead of the original image as well\n",
    "* In the end I went with the 7 epoch trained model because I had a good feeling it would be able to generalize well and was not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing in just the image, the MSE doesn't converge as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['image_path'].values[0], row['speed'].values[0], bright_factor)\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_valid_from_path(row['image_path'].values[0], row['speed'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDEAS: \n",
    "* Run forwards (img1 - img2) mean(speed)\n",
    "* Run backwards (img2 - img1) mean(speed)\n",
    "* Compute speed differential then apply prediction as: current_speed += speed_difference\n",
    "* speed_difference = xW + b\n",
    "* Optical Flow\n",
    "* Batch shuffler\n",
    "* Apply perspective transform\n",
    "* Sobely gradient \n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design considerations\n",
    "* Originally I generated a new brightness factor for each image, but that created some disturbances when I wanted to take the difference between both images so instead I used the same brightness augmentation for the current_frame and the next_frame. It works both ways though, it may have been better to make a random brightness augmentation because at one instant if our frame is under clear lighting, and the next frame has a shadow, we would not know how to consider that pixel difference. \n",
    "* I used a generator and yielded batches of my results, I did this so I didn't clog my memory stack while training my model\n",
    "* I took the input data and pushed the video images into a separate file and created a driving.csv file so I could use a pandas dataframe to read in each image path and only read in the image once I am in the generator. I could have just used moviepy and created a VideoFileClip and run all processing steps on each image, but I wouldn't have the same amount of control when testing out my preprocessing and data augmentation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate on subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload 14 epoch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-Vtest2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay prediction onto images and save to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlowOverlay(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    output: mask\n",
    "    \"\"\"\n",
    "    feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 5 )\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    mask = np.zeros_like(image_current)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel() # flatten\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.arrowedLine(mask, (a,b), (c, d), color[i].tolist(), 1, 8)\n",
    "        \n",
    "        image_next = cv2.circle(image_next_saved, (a, b), 1, color[i].tolist(), -1)\n",
    "        image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "        \n",
    "    dst = cv2.add(image_next, image_next_fg)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ./test_suite/data/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# given an input image\n",
    "\n",
    "data = pd.read_csv('./test_suite/data/v1.csv')\n",
    "for idx in range(1, len(data.index) - 1):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    \n",
    "#     aa = cv2.imread(\"./test_suite/data/IMG/0.033330000333300004.jpg\")\n",
    "#     print (row1['image_path'].values[0])\n",
    "#     cv2.imshow(\"Irtiza\",aa)\n",
    "    img_diff = x1 - x2\n",
    "                                   \n",
    "    # reshape image difference to feed into model.predict\n",
    "    img_diff = opticalFlowDense(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "        \n",
    "    # grab the mean speed y to check our model against\n",
    "    y = np.mean([y1, y2])\n",
    "    \n",
    "    # note: y2 is the actual speed of the frame x2 which we will use for accurate prediction, even though\n",
    "    # our model is based on x1 and x2\n",
    "                                   \n",
    "    # TODO: retrain model to evaluate y2 instead of mean(y1, y2) and check differences\n",
    "                                   \n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    error = abs(prediction - y2)\n",
    "    truth = y2\n",
    "                                       \n",
    "    predict_path = os.path.join('./test_suite/data/predict/', str(idx) + '.jpg')\n",
    "                                   \n",
    "    # overwrite the prediction of y2 onto image x2\n",
    "    # save overwritten image x2 to new directory ./data/predict\n",
    "\n",
    "#     print (\"Irtiz\")                      \n",
    "    # Make a copy \n",
    "    dst = np.copy(x2)\n",
    "    \n",
    "    dst = opticalFlowOverlay(x1, x2) \n",
    "    # This is a sparse optical flow overlay    \n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 10\n",
    "    FONT_SIZE = 0.3\n",
    "    THICKNESS = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(dst,'pred: ' + str(prediction[0][0])[:5],(5,offset), font, FONT_SIZE,(0,0,0), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst,'truth: ' + str(y2)[:5],(5,offset * 2), font, FONT_SIZE,(0,20,255), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst, 'error: ' + str(error[0][0])[:5], (5, offset*3),font, FONT_SIZE, (255, 0, 0), THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(predict_path, dst)\n",
    "    \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create video from sequence of images\n",
    "* These videos are from dense optical flow method, where I compute the dense optical flow and convert that to an rgb image and pass it into the network. There is a video for the 30 epoch non-optical flow model which is on youtube [here](http://www.youtube.com/embed/WofBjhlaWqQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "images = ['./test_suite/data/predict/' + str(i+1) + '.jpg' for i in range(0, 8614)]\n",
    "clip = ImageSequenceClip(images, fps=11.7552)\n",
    "clip.write_videofile(\"movie_vtest2.mp4\", fps=11.7552)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./data/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## movie_vtest1.mp4 (10 epoch MSE ~ 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_vtest.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is clearly overfit as you can see that the prediction is trying to predict high speeds during the freeway exit, but the ground truth happens to be set to a low speed. Here you can see that it attempts to predict the high speed but then it falls back down towards the ground truth speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movie vtest2 Video: Optical Flow Method 2, 15 epochs MSE: ~5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_vtest2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 Video Optical Flow Method, 16 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one may have overfit just a bit, bit it looks really nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For fun: Sparse Optical Flow Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3_sparseoverlay.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When I extract the image frames from the video file, I do so at a constant rate, splitting the 8616 frames evenly. In the ground truth dataset it is shown that images are not captured with a uniform sampling rate, so in each image, there is a slight error in the actual speed for that image. Meaning It will be unlikely that I can detect very rapid changes in speed.\n",
    "* I should have extracted the images using `ffmpeg -ss 0.5 -i inputfile.mp4 -t 1 -s 480x300 -f image2 imagefile.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Approaches\n",
    "* I notices this article: (http://nicolovaligi.com/car-speed-estimation-windshield-camera.html#Giachetti1999) and this code: (https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f) that uses Optical Flow to for Car Speed estimation using a single windshield camera. I copied the code, modified some fields so it worked with my dataset and ran it to see what happens.\n",
    "* An interesting thing to note is that in this code he is using ground truth data to calibrate the `hf` factor. Still, once the car goes on the freeway and deals with speeds > 30mph it fails completely. \n",
    "I ran the code with my dataset, which you can see in <strong>OpticalFlow.ipynb </strong>, and here is the result I got.\n",
    "* When I ran this code, I cropped out a ton of the image, meaning I lost a bunch of data. There are points when driving that the background and scenery can help define changes in velocity. Such as the difference in a trees position from one frame to the next, for this reason I went with the CNN approach.\n",
    "* Next steps: My next step is to compute the optical flow for each (current_image, next_frame) and feed that into my network as well. This way I can have the best of both worlds. Stay tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future considerations\n",
    "* If I had more time I would finish my DeepVO implementation [DeepVO](https://arxiv.org/pdf/1611.06069.pdf), which I started to write but did not finish. You can see DeepVO in <strong>DeepVO.ipynb</strong>\n",
    "* I would also try to implement [DeepFlow](http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.pdf) which claims to have great performance. \n",
    "* I would also consider trying [FlowNet](https://arxiv.org/pdf/1504.06852.pdf) and I would use this as a [guide] (https://github.com/ClementPinard/FlowNetPytorch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
